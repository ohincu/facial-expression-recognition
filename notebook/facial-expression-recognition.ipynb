{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and pre-processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot\n",
    "\n",
    "# Modeling CNN\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, BatchNormalization\n",
    "from keras.optimizers import adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Showing model results\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Loading model in a JSON file\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/icml_face_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing spaces in column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making emotions relatable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_label = {0:'anger', 1:'disgust', 2:'fear', 3:'happiness', 4: 'sadness', 5: 'surprise', 6: 'neutral'}\n",
    "df['emotion_label'] = df['emotion'].map(emotion_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.emotion_label.value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of our data has happy emotions. Across other emotions it's generally balanced,\n",
    "however happiness does make up a quarter of all the images, whereas the \"disgust\" being in minority, with around 1.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Usage\", \"emotion\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also no big differences in balance across test and training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before we continue, let's bear in mind that human emotions can be hard to identified even by humans, as they usually encompass a range of subtle differences in the face. The combination of the mouth, eyebrows, eyes, cheek movement, etc can mean the difference between sadness and happiness.  \n",
    "\n",
    "According to https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4873105/#:~:text=The%20emotions%20better%20recognized%20from,were%20more%20difficult%20to%20recognize, the hardest recognizable emotions are surprise, neutral and sadness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, (13, 13))\n",
    "k = 0\n",
    "for label in sorted(df.emotion.unique()):\n",
    "    for j in range(7):\n",
    "        px = df[df.emotion == label].pixels.iloc[k]\n",
    "        px = np.array(px.split(' ')).reshape(48, 48).astype('float32')\n",
    "\n",
    "        k += 1\n",
    "        ax = plt.subplot(7, 7, k)\n",
    "        ax.imshow(px, cmap = 'gray')\n",
    "        ax.set_title(emotion_label[label])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got baby and adult images, including character images.\n",
    "The faces are not only upright, but we can see instances where it's from the side\n",
    "or when they are covered. Probably the latest emotions would be harder to identify.\n",
    "Also, some images are labeled as \"happy\" that I would doubt that they are \"happy\".\n",
    "We are dealing with low-resolution pictures, which means we cannot expect a high level of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, for the model, consider only the anger - 0, happy - 3, sad - 4 emotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_labels = [0, 3, 4]\n",
    "df = df[df.emotion.isin(model_labels)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    img_array = np.zeros(shape = (len(df), 48, 48))\n",
    "    img_label = np.array(list(map(int, df['emotion'])))\n",
    "    \n",
    "    for i, row in enumerate(df.index):\n",
    "        img = np.fromstring(df.loc[row, 'pixels'], dtype = int, sep = ' ')\n",
    "        img = np.reshape(img, (48, 48))\n",
    "        img_array[i] = img\n",
    "    return img_array, img_label\n",
    "\n",
    "img_array_train, img_label_train = preprocess_data(df[df['Usage'] == 'Training'])\n",
    "img_array_val, img_label_val = preprocess_data(df[df['Usage'] == 'PrivateTest'])\n",
    "img_array_test, img_label_test = preprocess_data(df[df['Usage'] == 'PublicTest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the data into (batch_size, height, width, channels) for training neural networks with Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = img_array_train.reshape((img_array_train.shape[0], 48, 48, 1))\n",
    "x_test = img_array_test.reshape((img_array_test.shape[0], 48, 48, 1))\n",
    "x_val = img_array_val.reshape((img_array_val.shape[0], 48, 48, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "img_label_train = le.fit_transform(img_label_train)\n",
    "img_label_test = le.fit_transform(img_label_test)\n",
    "img_label_val = le.fit_transform(img_label_val)\n",
    "\n",
    "y_train = to_categorical(img_label_train)\n",
    "y_test = to_categorical(img_label_test)\n",
    "y_val = to_categorical(img_label_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the images to a [0,1] range ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "x_val = x_val.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, making sure everything looks consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape,x_val.shape,y_val.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # The images have low resolution therefore I use a small patch of 3,3.\n",
    "    Conv2D(32, (3, 3), activation = 'relu', input_shape = (48, 48, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    # We have 3 emotions, therefore 3 possible values in the output.\n",
    "    Dense(3, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = 'accuracy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include callbacks to avoid overfitting ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = EarlyStopping(monitor = 'val_accuracy', patience = 3, verbose = 1, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and for reducing the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 3, verbose = 1, min_lr = 0.0001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And augment just a bit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen.fit(x_train)\n",
    "\n",
    "history = model.fit(data_gen.flow(x_train, y_train),\n",
    "                    validation_data = (x_val, y_val),\n",
    "                    epochs = 20,\n",
    "                    batch_size = 32,\n",
    "                    callbacks = [stop, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reaches 76% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label = 'Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label = 'Training Loss')\n",
    "plt.plot(history.history['val_loss'], label = 'Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([0, 5])\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test, use_multiprocessing = True)\n",
    "acc_fc_orig = np.sum(np.argmax(y_test,axis=1) == np.argmax(predictions,axis=1)) / len(predictions)\n",
    "print(\"Acc_fc_orig = \" , acc_fc_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scikitplot.metrics.plot_confusion_matrix(np.argmax(y_test, axis = 1), np.argmax(predictions, axis = 1), figsize=(7,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a higher amount of False Positives for sad and angry emotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(np.argmax(y_test, axis = 1), np.argmax(predictions, axis = 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowest precision is for the \"angry\" faces. Let's see now side by side the predictions versus the \"true\" emotions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing happy and sad images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "happy_imgs = np.random.choice(np.where(y_test[:, 1] == 1)[0], size = 7)\n",
    "sad_imgs = np.random.choice(np.where(y_test[:, 2] == 1)[0], size = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, (12, 6))\n",
    "\n",
    "mapper = {\n",
    "    0: \"angry\",\n",
    "    1: \"happy\",\n",
    "    2: \"sad\"\n",
    "}\n",
    "\n",
    "for i, (happy, sad) in enumerate(zip(happy_imgs, sad_imgs)):\n",
    "        ax = plt.subplot(2, 7, i + 1)\n",
    "        sample_img = x_train[happy,:,:,0]\n",
    "        ax.imshow(sample_img, cmap = 'gray')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(f\"T:happy, P:{mapper[np.argmax(model.predict(sample_img.reshape(1,48,48,1)))]}\")\n",
    "        \n",
    "        ax = plt.subplot(2, 7, i + 8)\n",
    "        sample_img = x_train[sad,:,:,0]\n",
    "        ax.imshow(sample_img, cmap = 'gray')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(f\"T:sad, P:{mapper[np.argmax(model.predict(sample_img.reshape(1,48,48,1)))]}\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see again that some emotions are labeled as happy but looks as sad from a human eye.\n",
    "Our model seems to predict correctly for the wrongly labeled images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_model = model.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model architecture to the JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fer.json', 'w') as json_file:\n",
    "    json_file.write(json_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the model architecture from JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fer.json', 'r') as json_file:\n",
    "    JSON_saved_model = json_file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the weights of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('fer.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, model loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,acc = model.evaluate(x_test,  y_test, verbose = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
